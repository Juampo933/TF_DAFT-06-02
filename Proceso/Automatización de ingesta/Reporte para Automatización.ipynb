{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proceso de Automatización para ANY Manufacturing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configuración de la conexión a la base de datos.\n",
    "\n",
    "Se definen las credenciales para la empresa de la base de datos (servidor, nombre de la base de datos, usuario y contraseña).\n",
    "Se construye una cadena de conexión (connection_string) usando sqlalchemy.create_engine, que permite conectar y ejecutar consultas SQL en la base de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "database_config = {\n",
    "    'server':'servidor',\n",
    "    'database': 'Base de datos para la empresa',\n",
    "    'username': 'Usuario',\n",
    "    'password': 'Contraseña',\n",
    "    'driver': '{ODBC Driver 17 for SQL Server}'\n",
    "}\n",
    "connection_string = f\"mssql+pyodbc://{database_config['username']}:{database_config['password']}@{database_config['server']}/{database_config['database']}?driver=ODBC+Driver+17+for+SQL+Server\"\n",
    "engine = create_engine(connection_string)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clase DataHandler para manejar eventos de archivos: Esta clase personalizada, DataHandler, hereda de FileSystemEventHandler de watchdog, y responde a eventos de creación y modificación de archivos en una carpeta específica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataHandler(FileSystemEventHandler):\n",
    "    def __init__(self, engine):\n",
    "        self.engine = engine\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Procesamiento de nuevos archivos: Los métodos on_created y on_modified verifican si el archivo es un .csv, y si es así, llaman a process_new_file, donde se carga el archivo y se preparan los datos para su inserción en la base de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_created(self, event):\n",
    "    if event.is_directory or not event.src_path.endswith(\".csv\"):\n",
    "        return\n",
    "    self.process_new_file(event.src_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inserción de datos en SQL: En process_new_file, el archivo .csv se carga en un DataFrame, convirtiendo columnas con fechas y eliminando columnas no deseadas como Unnamed: 0. Luego, la tabla SQL correspondiente y la columna ID se determinan mediante get_id_column, y se identifican los registros nuevos que no están ya en la tabla."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_new_file(self, file_path):\n",
    "    new_data = pd.read_csv(file_path)\n",
    "    new_data = new_data.drop(columns=['Unnamed: 0'], errors='ignore')\n",
    "    for column in new_data.columns:\n",
    "        if 'date' in column.lower():\n",
    "            new_data[column] = pd.to_datetime(new_data[column], errors='coerce')\n",
    "    # Identificación de filas nuevas e inserción\n",
    "    new_rows = new_data[~new_data[id_column].isin(existing_data[id_column])]\n",
    "    new_rows.to_sql(table_name, self.engine, if_exists='append', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Monitorización continua de archivos: En el bloque principal (__main__), Observer monitoriza una carpeta específica, path_to_watch. Los archivos existentes en esta carpeta se procesan inicialmente con process_existing_files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_watch = r\"C:\\Users\\Admin\\Desktop\\proyecto final\\Proceso\\CSV listos\"\n",
    "observer = Observer()\n",
    "observer.schedule(event_handler, path=path_to_watch, recursive=True)\n",
    "observer.start()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este flujo automatiza el proceso de carga y actualización de datos en SQL Server, optimizando la integración y gestión de archivos .csv en tiempo real."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
