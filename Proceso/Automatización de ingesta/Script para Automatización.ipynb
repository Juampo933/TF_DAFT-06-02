{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Script para la Automatización de ingesta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import pyodbc\n",
    "from sqlalchemy import create_engine\n",
    "from watchdog.observers import Observer\n",
    "from watchdog.events import FileSystemEventHandler\n",
    "\n",
    "#Para la seguridad de credenciales\n",
    "password = os.environ['dbpassword']\n",
    "\n",
    "# Configuración de la base de datos\n",
    "database_config = {\n",
    "    'server':'anyd.database.windows.net', \n",
    "    'database': 'ANY_D',  \n",
    "    'username': 'admin-any' ,\n",
    "    'password': password , \n",
    "    'driver': '{ODBC Driver 17 for SQL Server}' \n",
    "}\n",
    "\n",
    "# Crear cadena de conexión\n",
    "connection_string = f\"mssql+pyodbc://{database_config['username']}:{database_config['password']}@{database_config['server']}/{database_config['database']}?driver=ODBC+Driver+17+for+SQL+Server\"\n",
    "engine = create_engine(connection_string)\n",
    "\n",
    "# Verificación de conexión\n",
    "try:\n",
    "    engine.connect()\n",
    "    print(\"Conexión exitosa a la base de datos\")\n",
    "except Exception as e:\n",
    "    print(f\"Error en la conexión: {e}\")\n",
    "\n",
    "class DataHandler(FileSystemEventHandler):\n",
    "    def __init__(self, engine):\n",
    "        self.engine = engine\n",
    "\n",
    "    def on_created(self, event):\n",
    "        if event.is_directory or not event.src_path.endswith(\".csv\"):\n",
    "            return\n",
    "        self.process_new_file(event.src_path)\n",
    "\n",
    "    def on_modified(self, event):\n",
    "        if event.is_directory or not event.src_path.endswith(\".csv\"):\n",
    "            return\n",
    "        self.process_new_file(event.src_path)\n",
    "\n",
    "    def process_new_file(self, file_path):\n",
    "        print(f\"Procesando el archivo: {file_path}\")\n",
    "        try:\n",
    "            new_data = pd.read_csv(file_path)\n",
    "            print(f\"Datos cargados desde {file_path}\")\n",
    "\n",
    "            new_data = new_data.drop(columns=['Unnamed: 0'], errors='ignore')\n",
    "\n",
    "            # Convertir columnas que contengan la palabra 'date' a formato datetime\n",
    "            for column in new_data.columns:\n",
    "                if 'date' in column.lower():\n",
    "                    new_data[column] = pd.to_datetime(new_data[column], errors='coerce')\n",
    "\n",
    "            table_name = os.path.splitext(os.path.basename(file_path))[0]\n",
    "            print(f\"Tabla detectada: {table_name}\")\n",
    "\n",
    "            # Obtener el nombre de la columna ID específica\n",
    "            id_column = self.get_id_column(table_name)\n",
    "\n",
    "            # Verificar que la columna ID exista en el DataFrame\n",
    "            if id_column not in new_data.columns:\n",
    "                print(f\"Error: La columna '{id_column}' no existe en el archivo {file_path}\")\n",
    "                return\n",
    "\n",
    "            # Cargar los datos existentes de la base de datos\n",
    "            print(f\"Cargando datos existentes de la tabla {table_name} desde la base de datos...\")\n",
    "            existing_data = pd.read_sql(f\"SELECT * FROM {table_name}\", self.engine)\n",
    "            print(f\"Datos existentes cargados de la tabla {table_name}\")\n",
    "\n",
    "            #Obetener ID maximo de la tabla\n",
    "            valormaximo = existing_data[id_column].max()\n",
    "            print(existing_data)\n",
    "\n",
    "            # Identificar filas nuevas (basado en id_column)\n",
    "            new_rows = new_data[~new_data[id_column].isin(existing_data[id_column])]\n",
    "\n",
    "            #Remplaza el valor de id_columun con el maximo valor de la tabla en base e autoincrementa +1\n",
    "            new_rows[id_column] = range(valormaximo + 1, valormaximo + 1 + len(new_rows))\n",
    "\n",
    "            # Imprimir las filas nuevas detectadas\n",
    "            print(\"Filas nuevas identificadas:\")\n",
    "            print(new_rows)\n",
    "\n",
    "            # Insertar datos nuevos en la base de datos\n",
    "            if not new_rows.empty:\n",
    "                print(f\"Insertando {len(new_rows)} filas nuevas en la tabla {table_name}...\")\n",
    "                new_rows.to_sql(table_name, self.engine, if_exists='append', index=False)\n",
    "                print(f\"Se han insertado {len(new_rows)} filas nuevas en la tabla {table_name}\")\n",
    "            else:\n",
    "                print(f\"No hay filas nuevas para insertar en la tabla {table_name}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error al procesar el archivo {file_path}: {e}\")\n",
    "\n",
    "    def get_id_column(self, table_name):\n",
    "        id_columns = {\n",
    "            'BeginInventory': 'BeginInventoryID',\n",
    "            'FinalInventory': 'FinalInventoryID',\n",
    "            'InvoicePurchases': 'PurchaseID',\n",
    "            'Products': 'BrandID',\n",
    "            'PurchasesFinal': 'PurchasesFinalID',\n",
    "            'SalesFinal': 'SalesID',\n",
    "        }\n",
    "        return id_columns.get(table_name, 'id')\n",
    "\n",
    "def process_existing_files(path, handler):\n",
    "    for filename in os.listdir(path):\n",
    "        if filename.endswith(\".csv\"):\n",
    "            file_path = os.path.join(path, filename)\n",
    "            handler.process_new_file(file_path)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    path_to_watch = r\"C:\\Users\\Admin\\Desktop\\proyecto final\\Proceso\\CSV listos\" \n",
    "    event_handler = DataHandler(engine)\n",
    "\n",
    "    # Procesar archivos existentes en la carpeta\n",
    "    print(\"Procesando archivos existentes en la carpeta...\")\n",
    "    process_existing_files(path_to_watch, event_handler)\n",
    "\n",
    "    observer = Observer()\n",
    "    observer.schedule(event_handler, path=path_to_watch, recursive=True)\n",
    "    observer.start()\n",
    "    print(f\"Observando cambios en: {path_to_watch}\")\n",
    "\n",
    "    try:\n",
    "        while True:\n",
    "            time.sleep(1)\n",
    "    except KeyboardInterrupt:\n",
    "        observer.stop()\n",
    "    observer.join()\n",
    "    print(\"El observador ha sido detenido.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
